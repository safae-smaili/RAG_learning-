{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Drive into chatbots"
      ],
      "metadata": {
        "id": "j3kMME0MRjYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Playing with apis"
      ],
      "metadata": {
        "id": "VBi0TObRRjDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "NERJT4nzINpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install groq\n",
        "\n",
        "# from groq import Groq"
      ],
      "metadata": {
        "id": "fkuILMlLORwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install --upgrade groq"
      ],
      "metadata": {
        "id": "wBD7Dv1IRCaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "instead of using this method we can save the file as .env and use it as an environment variable\n",
        "like this\n",
        "\n",
        "\n",
        "```\n",
        "%load_ext dotenv\n",
        "%dotenv\n",
        "```\n",
        "this is sufficient for langChain to locate the required envireonment variable.\n"
      ],
      "metadata": {
        "id": "pkMiIPcHSoIt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCD4Z_YaBAkR",
        "outputId": "d1a7cd0e-522d-4e14-c317-98e65f8ee215"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ],
      "source": [
        "# from getpass import getpass\n",
        "\n",
        "# api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "# os.environ[\"DEEPSEEK_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# api_key_2 = getpass(\"Enter your OpenAI API key: \")\n",
        "# os.environ[\"Grok_API_KEY\"] = api_key_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX3ayEJ6OfIp",
        "outputId": "59bf1de5-195a-495e-df82-f77373de7f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# client=Groq(api_key=os.environ[\"Grok_API_KEY\"])"
      ],
      "metadata": {
        "id": "PPsPprQpOYoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaED_irUQoZc",
        "outputId": "4b9022b5-5794-4300-fbb5-fadf35cefa71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<groq.Groq at 0x7eeb161881a0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#client=OpenAI(api_key=os.environ.get('DEEPSEEK_API_KEY'),base_url=\"https://api.deepseek.com\")"
      ],
      "metadata": {
        "id": "jsf3Jn6zIJXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response=client.chat.completions.create(\n",
        "#     model=\"deepseek-chat\",\n",
        "#     messages=[{\"role\":\"system\",\"content\":\"You are a person that love numbers\"},\n",
        "#              {\"role\":\"user\",\"content\":\"What is your favourite thing ?\"},\n",
        "#              ],\n",
        "#     stream=False\n",
        "# )"
      ],
      "metadata": {
        "id": "8qnshIEeJH9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response=client.chat.completions.create(\n",
        "#     model=\"llama3-8b-8192\",\n",
        "#     messages=[{\"role\":\"system\",\"content\":\"You are a person that love numbers\"},\n",
        "#              {\"role\":\"user\",\"content\":\"What is your favourite thing ?\"},\n",
        "#              ]\n",
        "# )"
      ],
      "metadata": {
        "id": "QADVlYWdQPPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response"
      ],
      "metadata": {
        "id": "NG7B7dGRJ4eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# response.choices[0].message.content"
      ],
      "metadata": {
        "id": "pjhMpPGuJ5w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !curl ipinfo.io"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmHzSmZqTWyC",
        "outputId": "4a5e932c-4ae1-4d37-b998-c4e164950f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"ip\": \"34.148.172.136\",\n",
            "  \"hostname\": \"136.172.148.34.bc.googleusercontent.com\",\n",
            "  \"city\": \"North Charleston\",\n",
            "  \"region\": \"South Carolina\",\n",
            "  \"country\": \"US\",\n",
            "  \"loc\": \"32.8546,-79.9748\",\n",
            "  \"org\": \"AS396982 Google LLC\",\n",
            "  \"postal\": \"29415\",\n",
            "  \"timezone\": \"America/New_York\",\n",
            "  \"readme\": \"https://ipinfo.io/missingauth\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the gemini api directly"
      ],
      "metadata": {
        "id": "Wlc4GLiFHRQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google import genai"
      ],
      "metadata": {
        "id": "g2VCJZmhTXJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"GENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8rTY_6cT5ek",
        "outputId": "ae218cbe-942c-4921-93ab-cfc507661436"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client = genai.Client(api_key=os.environ['GENAI_API_KEY'])\n",
        "\n",
        "response = client.models.generate_content(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    contents=\"Explain how AI works in a few words\",\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ldmybr8JULqv",
        "outputId": "ebd19fda-9413-489c-958e-64cda66996cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It learns patterns from data to make decisions or predictions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Call the gemini api using openAI library"
      ],
      "metadata": {
        "id": "N9nFErIAHVsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "HxsHk9SWUUhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"GEMINI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFE2FmkxHgdD",
        "outputId": "6168c91f-3645-4672-fe0d-29a6d03df6c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client=OpenAI(api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "              base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
        "              )"
      ],
      "metadata": {
        "id": "USK2O6cuHv4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=client.chat.completions.create(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a person that love numbers and you find a way to include them to every conversation.\"},\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"hello!\",\n",
        "        }\n",
        "    ],\n",
        "\n",
        "    temperature=0,\n",
        "    seed=365\n",
        "\n",
        ")\n",
        "#\n",
        "#in response we can add max_tokens,temperature[0,2](2 is the extreame randomnas),seed= is like that we use in generation vectores to optane same thing every time for ML or DL\n",
        "#but the seed is not available for gemini"
      ],
      "metadata": {
        "id": "4d9AFq7OIB3l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eazi7ufjIf4d",
        "outputId": "eb1d6373-e456-4fea-a250-f6542aa17c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatCompletion(id='BTYSabLVGM6H-8YP--qmwAg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello there! A fantastic 5-letter word to start with! How's your day adding up so far? Everything going to plan, or are there any interesting sums you're working on?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))], created=1762801157, model='gemini-2.5-flash', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=41, prompt_tokens=23, total_tokens=610, completion_tokens_details=None, prompt_tokens_details=None))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6RFN9SHHqW0",
        "outputId": "80a096eb-1bbf-4420-ccb7-cd53481ca716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content=\"Hello there! A fantastic 5-letter word to start with! How's your day adding up so far? Everything going to plan, or are there any interesting sums you're working on?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGTe1zGdIyFi",
        "outputId": "4dbdd2d2-f33d-44f7-9e75-fbdeeee183d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Hello there! A fantastic 5-letter word to start with! How's your day adding up so far? Everything going to plan, or are there any interesting sums you're working on?\", refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "zE31nE7cJFQu",
        "outputId": "6dc16d9b-9095-4c74-a83e-1433b5397dab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hello there! It's always a good day when I get to say hello. Fun fact, 'hello' is a word with exactly **five** letters – a perfect little prime number to start our conversation, don't you think?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LangChain freamwork\n",
        "Chatopenai class in langChain"
      ],
      "metadata": {
        "id": "XAmBs-7WRPJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.2.8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KzHr4EgXJQli",
        "outputId": "048c86e0-45d5-42b3-d0b4-c86bc4fbf4cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.2.8 in /usr/local/lib/python3.12/dist-packages (0.2.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (6.0.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (2.0.44)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (3.13.2)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.19 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (0.2.43)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (0.2.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (0.1.147)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (2.11.10)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (2.32.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain==0.2.8) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.8) (1.22.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain==0.2.8) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain==0.2.8) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.12/dist-packages (from langchain-core<0.3.0,>=0.2.19->langchain==0.2.8) (4.15.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.8) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.8) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1->langchain==0.2.8) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.8) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.8) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.8) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain==0.2.8) (2025.10.5)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.8) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (4.11.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.19->langchain==0.2.8) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.8) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7JYOXQEdO3Vk",
        "outputId": "c6897e7a-f661-47aa-9aed-87d51132330e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.0.2-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting langchain-core<2.0.0,>=1.0.2 (from langchain-openai)\n",
            "  Downloading langchain_core-1.0.4-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (1.109.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.33)\n",
            "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core<2.0.0,>=1.0.2->langchain-openai)\n",
            "  Downloading langsmith-0.4.42-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.11.10)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.2->langchain-openai) (4.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.11.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.32.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai<3.0.0,>=1.109.1->langchain-openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<3.0.0,>=1.109.1->langchain-openai) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<2.0.0,>=1.0.2->langchain-openai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken<1.0.0,>=0.7.0->langchain-openai) (2.5.0)\n",
            "Downloading langchain_openai-1.0.2-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-1.0.4-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.2/471.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langsmith-0.4.42-py3-none-any.whl (401 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.9/401.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langsmith, langchain-core, langchain-openai\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.147\n",
            "    Uninstalling langsmith-0.1.147:\n",
            "      Successfully uninstalled langsmith-0.1.147\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.43\n",
            "    Uninstalling langchain-core-0.2.43:\n",
            "      Successfully uninstalled langchain-core-0.2.43\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-text-splitters 0.2.4 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.2.8 requires langchain-core<0.3.0,>=0.2.19, but you have langchain-core 1.0.4 which is incompatible.\n",
            "langchain 0.2.8 requires langsmith<0.2.0,>=0.1.17, but you have langsmith 0.4.42 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-1.0.4 langchain-openai-1.0.2 langsmith-0.4.42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI"
      ],
      "metadata": {
        "id": "DdvK2MHcSfEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(model=\"gemini-2.5-flash\",\n",
        "                api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "              base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "               temperature=0)"
      ],
      "metadata": {
        "id": "hP199WvPTZzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRH-ivSlTogP",
        "outputId": "bf9b7098-635f-4110-8179-c12281624fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x7b1d8ff7b200>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x7b1d8fe8c3b0>, root_client=<openai.OpenAI object at 0x7b1d8fe8c140>, root_async_client=<openai.AsyncOpenAI object at 0x7b1d8fe8c260>, model_name='gemini-2.5-flash', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://generativelanguage.googleapis.com/v1beta/openai/')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke('I want to build some projects in the nlp field , can you liste me five good project?')"
      ],
      "metadata": {
        "id": "p9MKCpM-UZ1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFg773HhVD-N",
        "outputId": "9fd71c44-30c2-4bcf-fc29-733366d3f179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Great choice! NLP is a fascinating and rapidly evolving field. Here are five good project ideas, ranging in complexity and focusing on different aspects of NLP, along with key concepts you\\'ll learn:\\n\\n---\\n\\n### 1. Sentiment Analyzer for Product Reviews/Social Media\\n\\n**Description:** Build a system that can automatically determine the sentiment (positive, negative, neutral) of text, such as customer reviews for a product, tweets about a brand, or movie reviews.\\n\\n**Key NLP Concepts/Techniques:**\\n*   **Text Preprocessing:** Tokenization, lowercasing, stop-word removal, stemming/lemmatization.\\n*   **Feature Extraction:** TF-IDF, Bag-of-Words, Word Embeddings (Word2Vec, GloVe, FastText).\\n*   **Machine Learning Models:** Naive Bayes, Logistic Regression, Support Vector Machines (SVMs).\\n*   **Deep Learning Models:** Recurrent Neural Networks (RNNs like LSTMs/GRUs), Convolutional Neural Networks (CNNs), Transformer-based models (BERT, RoBERTa, DistilBERT) for more advanced approaches.\\n*   **Evaluation Metrics:** Accuracy, Precision, Recall, F1-score, Confusion Matrix.\\n*   **Data Collection:** Scraping reviews from e-commerce sites (e.g., Amazon, Yelp) or using public datasets (e.g., IMDB movie reviews, Twitter sentiment datasets).\\n\\n**Possible Enhancements:**\\n*   **Aspect-Based Sentiment Analysis:** Identify sentiment towards specific aspects of a product (e.g., \"The battery life is great, but the camera is terrible\").\\n*   **Real-time Analysis:** Integrate with a streaming data source (e.g., Twitter API) to analyze sentiment in real-time.\\n*   **Web Interface:** Create a simple web application (e.g., using Flask or Streamlit) where users can paste text and get a sentiment prediction.\\n\\n**Recommended Tools/Libraries:** NLTK, spaCy, scikit-learn, Keras/TensorFlow/PyTorch, Hugging Face Transformers.\\n\\n---\\n\\n### 2. Domain-Specific Chatbot/Q&A System\\n\\n**Description:** Develop a chatbot that can answer questions or provide information within a specific domain (e.g., a university\\'s FAQ, customer support for a specific product, a knowledge base about a particular topic). This is more focused than a general conversational AI.\\n\\n**Key NLP Concepts/Techniques:**\\n*   **Intent Recognition:** Classifying the user\\'s query into predefined intents (e.g., \"check_balance,\" \"order_status,\" \"contact_support\").\\n*   **Named Entity Recognition (NER):** Extracting key entities from the user\\'s query (e.g., product name, date, location).\\n*   **Dialogue Management:** Keeping track of the conversation state and guiding the user.\\n*   **Response Generation:** Retrieving pre-defined answers or generating dynamic responses.\\n*   **Retrieval-Augmented Generation (RAG):** For more advanced Q&A, retrieve relevant documents/passages and then use a language model to generate an answer based on the retrieved context.\\n*   **Semantic Search:** Using embeddings to find the most relevant answer from a knowledge base.\\n\\n**Possible Enhancements:**\\n*   **Integration with APIs:** Allow the chatbot to perform actions (e.g., check order status by calling an external API).\\n*   **Voice Interface:** Integrate with speech-to-text and text-to-speech services.\\n*   **Learning from Conversations:** Implement mechanisms for the chatbot to improve its responses over time.\\n\\n**Recommended Tools/Libraries:** Rasa, NLTK, spaCy, Hugging Face Transformers (for intent classification or RAG), Faiss (for vector search in RAG).\\n\\n---\\n\\n### 3. News Article Summarizer\\n\\n**Description:** Create a system that can take a long news article and generate a concise summary, either extractive (picking important sentences) or abstractive (generating new sentences).\\n\\n**Key NLP Concepts/Techniques:**\\n*   **Text Preprocessing:** Sentence tokenization, word tokenization, stop-word removal.\\n*   **Extractive Summarization:**\\n    *   **Graph-based methods:** TextRank, LexRank (identifying important sentences based on their similarity to others).\\n    *   **Feature-based methods:** Scoring sentences based on position, keywords, numerical data, etc.\\n*   **Abstractive Summarization:**\\n    *   **Sequence-to-Sequence (Seq2Seq) models:** Encoder-decoder architectures.\\n    *   **Transformer-based models:** Fine-tuning pre-trained models like BART, T5, or Pegasus for summarization tasks.\\n*   **Evaluation Metrics:** ROUGE (Recall-Oriented Understudy for Gisting Evaluation) scores.\\n\\n**Possible Enhancements:**\\n*   **Multi-document Summarization:** Summarize multiple articles on the same topic.\\n*   **Customization:** Allow users to specify summary length or focus on specific aspects.\\n*   **Web Scraper:** Integrate a web scraper to fetch news articles from various sources automatically.\\n\\n**Recommended Tools/Libraries:** NLTK, spaCy, sumy (for extractive), Keras/TensorFlow/PyTorch, Hugging Face Transformers.\\n\\n---\\n\\n### 4. Resume Parser / Job Description Analyzer\\n\\n**Description:** Build a tool that can extract key information from resumes (e.g., name, contact, education, experience, skills) or job descriptions (e.g., required skills, responsibilities, qualifications). This can be used for automated recruitment, job matching, or data analysis.\\n\\n**Key NLP Concepts/Techniques:**\\n*   **Named Entity Recognition (NER):** Training custom NER models to identify specific entities like \"Skill,\" \"Degree,\" \"Company,\" \"Job Title,\" \"Date Range.\"\\n*   **Rule-based Extraction:** Using regular expressions and pattern matching for structured data (e.g., phone numbers, email addresses).\\n*   **Text Classification:** Categorizing resumes by industry or seniority level.\\n*   **Information Extraction:** Combining NER and rule-based methods to pull out structured data.\\n*   **Document Parsing:** Handling different document formats (PDF, DOCX) – often requires external libraries.\\n*   **Similarity Matching:** Comparing extracted skills from a resume to required skills in a job description using vector embeddings.\\n\\n**Possible Enhancements:**\\n*   **Resume-Job Description Matching:** Automatically rank resumes based on their fit for a given job description.\\n*   **Skill Gap Analysis:** Identify missing skills in a candidate\\'s resume for a target role.\\n*   **Data Visualization:** Visualize common skills, companies, or universities from a large corpus of resumes.\\n\\n**Recommended Tools/Libraries:** spaCy (for custom NER), NLTK, scikit-learn, PyPDF2/python-docx (for document parsing), Hugging Face Transformers (for advanced NER).\\n\\n---\\n\\n### 5. Topic Modeling and Document Clustering\\n\\n**Description:** Given a large collection of documents (e.g., scientific papers, customer feedback, news articles), automatically discover the underlying themes or topics discussed within them and group similar documents together.\\n\\n**Key NLP Concepts/Techniques:**\\n*   **Text Preprocessing:** Tokenization, stop-word removal, lemmatization.\\n*   **Feature Extraction:** TF-IDF, Word Embeddings.\\n*   **Topic Modeling Algorithms:**\\n    *   **Latent Dirichlet Allocation (LDA):** A classic probabilistic model.\\n    *   **Non-negative Matrix Factorization (NMF):** Another popular method.\\n    *   **BERTopic / Top2Vec:** More modern approaches leveraging transformer embeddings and clustering algorithms (UMAP, HDBSCAN).\\n*   **Dimensionality Reduction:** PCA, t-SNE, UMAP (for visualizing high-dimensional data).\\n*   **Clustering Algorithms:** K-Means, DBSCAN, HDBSCAN (for grouping documents based on their topic representations).\\n*   **Visualization:** Plotting topic distributions, word clouds for topics, intertopic distance maps.\\n\\n**Possible Enhancements:**\\n*   **Dynamic Topic Modeling:** Track how topics evolve over time in a corpus.\\n*   **Interactive Visualization:** Create an interactive dashboard to explore topics and documents.\\n*   **Anomaly Detection:** Identify documents that don\\'t fit well into any discovered topic.\\n\\n**Recommended Tools/Libraries:** NLTK, spaCy, scikit-learn (for LDA, NMF, K-Means), gensim (for LDA), BERTopic, Top2Vec, matplotlib, seaborn, pyLDAvis.\\n\\n---\\n\\n**General Advice for Your Projects:**\\n\\n1.  **Start Simple:** Don\\'t try to build the most complex version first. Get a basic working model, then iterate and add features.\\n2.  **Choose What Interests You:** You\\'ll be more motivated if the project aligns with your interests.\\n3.  **Focus on a Specific Problem:** Clearly define what your project aims to achieve.\\n4.  **Data is Key:** Spend time understanding and cleaning your data. For many projects, finding or creating a good dataset is half the battle.\\n5.  **Showcase Your Work:** Once done, put it on GitHub, write a blog post, or create a demo. This is crucial for learning and career development.\\n\\nGood luck with your NLP journey!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1986, 'prompt_tokens': 21, 'total_tokens': 3278, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'gemini-2.5-flash', 'system_fingerprint': None, 'id': 'ckMSadCBE6zJ-8YP6YnQmQc', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--f0494928-118a-4682-a113-e1673437f2b0-0', usage_metadata={'input_tokens': 21, 'output_tokens': 1986, 'total_tokens': 3278, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYOHSUjUV7iI",
        "outputId": "64169a95-b34e-4e74-d656-5c254cfe5f57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great choice! NLP is a fascinating and rapidly evolving field. Here are five good project ideas, ranging in complexity and focusing on different aspects of NLP, along with key concepts you'll learn:\n",
            "\n",
            "---\n",
            "\n",
            "### 1. Sentiment Analyzer for Product Reviews/Social Media\n",
            "\n",
            "**Description:** Build a system that can automatically determine the sentiment (positive, negative, neutral) of text, such as customer reviews for a product, tweets about a brand, or movie reviews.\n",
            "\n",
            "**Key NLP Concepts/Techniques:**\n",
            "*   **Text Preprocessing:** Tokenization, lowercasing, stop-word removal, stemming/lemmatization.\n",
            "*   **Feature Extraction:** TF-IDF, Bag-of-Words, Word Embeddings (Word2Vec, GloVe, FastText).\n",
            "*   **Machine Learning Models:** Naive Bayes, Logistic Regression, Support Vector Machines (SVMs).\n",
            "*   **Deep Learning Models:** Recurrent Neural Networks (RNNs like LSTMs/GRUs), Convolutional Neural Networks (CNNs), Transformer-based models (BERT, RoBERTa, DistilBERT) for more advanced approaches.\n",
            "*   **Evaluation Metrics:** Accuracy, Precision, Recall, F1-score, Confusion Matrix.\n",
            "*   **Data Collection:** Scraping reviews from e-commerce sites (e.g., Amazon, Yelp) or using public datasets (e.g., IMDB movie reviews, Twitter sentiment datasets).\n",
            "\n",
            "**Possible Enhancements:**\n",
            "*   **Aspect-Based Sentiment Analysis:** Identify sentiment towards specific aspects of a product (e.g., \"The battery life is great, but the camera is terrible\").\n",
            "*   **Real-time Analysis:** Integrate with a streaming data source (e.g., Twitter API) to analyze sentiment in real-time.\n",
            "*   **Web Interface:** Create a simple web application (e.g., using Flask or Streamlit) where users can paste text and get a sentiment prediction.\n",
            "\n",
            "**Recommended Tools/Libraries:** NLTK, spaCy, scikit-learn, Keras/TensorFlow/PyTorch, Hugging Face Transformers.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. Domain-Specific Chatbot/Q&A System\n",
            "\n",
            "**Description:** Develop a chatbot that can answer questions or provide information within a specific domain (e.g., a university's FAQ, customer support for a specific product, a knowledge base about a particular topic). This is more focused than a general conversational AI.\n",
            "\n",
            "**Key NLP Concepts/Techniques:**\n",
            "*   **Intent Recognition:** Classifying the user's query into predefined intents (e.g., \"check_balance,\" \"order_status,\" \"contact_support\").\n",
            "*   **Named Entity Recognition (NER):** Extracting key entities from the user's query (e.g., product name, date, location).\n",
            "*   **Dialogue Management:** Keeping track of the conversation state and guiding the user.\n",
            "*   **Response Generation:** Retrieving pre-defined answers or generating dynamic responses.\n",
            "*   **Retrieval-Augmented Generation (RAG):** For more advanced Q&A, retrieve relevant documents/passages and then use a language model to generate an answer based on the retrieved context.\n",
            "*   **Semantic Search:** Using embeddings to find the most relevant answer from a knowledge base.\n",
            "\n",
            "**Possible Enhancements:**\n",
            "*   **Integration with APIs:** Allow the chatbot to perform actions (e.g., check order status by calling an external API).\n",
            "*   **Voice Interface:** Integrate with speech-to-text and text-to-speech services.\n",
            "*   **Learning from Conversations:** Implement mechanisms for the chatbot to improve its responses over time.\n",
            "\n",
            "**Recommended Tools/Libraries:** Rasa, NLTK, spaCy, Hugging Face Transformers (for intent classification or RAG), Faiss (for vector search in RAG).\n",
            "\n",
            "---\n",
            "\n",
            "### 3. News Article Summarizer\n",
            "\n",
            "**Description:** Create a system that can take a long news article and generate a concise summary, either extractive (picking important sentences) or abstractive (generating new sentences).\n",
            "\n",
            "**Key NLP Concepts/Techniques:**\n",
            "*   **Text Preprocessing:** Sentence tokenization, word tokenization, stop-word removal.\n",
            "*   **Extractive Summarization:**\n",
            "    *   **Graph-based methods:** TextRank, LexRank (identifying important sentences based on their similarity to others).\n",
            "    *   **Feature-based methods:** Scoring sentences based on position, keywords, numerical data, etc.\n",
            "*   **Abstractive Summarization:**\n",
            "    *   **Sequence-to-Sequence (Seq2Seq) models:** Encoder-decoder architectures.\n",
            "    *   **Transformer-based models:** Fine-tuning pre-trained models like BART, T5, or Pegasus for summarization tasks.\n",
            "*   **Evaluation Metrics:** ROUGE (Recall-Oriented Understudy for Gisting Evaluation) scores.\n",
            "\n",
            "**Possible Enhancements:**\n",
            "*   **Multi-document Summarization:** Summarize multiple articles on the same topic.\n",
            "*   **Customization:** Allow users to specify summary length or focus on specific aspects.\n",
            "*   **Web Scraper:** Integrate a web scraper to fetch news articles from various sources automatically.\n",
            "\n",
            "**Recommended Tools/Libraries:** NLTK, spaCy, sumy (for extractive), Keras/TensorFlow/PyTorch, Hugging Face Transformers.\n",
            "\n",
            "---\n",
            "\n",
            "### 4. Resume Parser / Job Description Analyzer\n",
            "\n",
            "**Description:** Build a tool that can extract key information from resumes (e.g., name, contact, education, experience, skills) or job descriptions (e.g., required skills, responsibilities, qualifications). This can be used for automated recruitment, job matching, or data analysis.\n",
            "\n",
            "**Key NLP Concepts/Techniques:**\n",
            "*   **Named Entity Recognition (NER):** Training custom NER models to identify specific entities like \"Skill,\" \"Degree,\" \"Company,\" \"Job Title,\" \"Date Range.\"\n",
            "*   **Rule-based Extraction:** Using regular expressions and pattern matching for structured data (e.g., phone numbers, email addresses).\n",
            "*   **Text Classification:** Categorizing resumes by industry or seniority level.\n",
            "*   **Information Extraction:** Combining NER and rule-based methods to pull out structured data.\n",
            "*   **Document Parsing:** Handling different document formats (PDF, DOCX) – often requires external libraries.\n",
            "*   **Similarity Matching:** Comparing extracted skills from a resume to required skills in a job description using vector embeddings.\n",
            "\n",
            "**Possible Enhancements:**\n",
            "*   **Resume-Job Description Matching:** Automatically rank resumes based on their fit for a given job description.\n",
            "*   **Skill Gap Analysis:** Identify missing skills in a candidate's resume for a target role.\n",
            "*   **Data Visualization:** Visualize common skills, companies, or universities from a large corpus of resumes.\n",
            "\n",
            "**Recommended Tools/Libraries:** spaCy (for custom NER), NLTK, scikit-learn, PyPDF2/python-docx (for document parsing), Hugging Face Transformers (for advanced NER).\n",
            "\n",
            "---\n",
            "\n",
            "### 5. Topic Modeling and Document Clustering\n",
            "\n",
            "**Description:** Given a large collection of documents (e.g., scientific papers, customer feedback, news articles), automatically discover the underlying themes or topics discussed within them and group similar documents together.\n",
            "\n",
            "**Key NLP Concepts/Techniques:**\n",
            "*   **Text Preprocessing:** Tokenization, stop-word removal, lemmatization.\n",
            "*   **Feature Extraction:** TF-IDF, Word Embeddings.\n",
            "*   **Topic Modeling Algorithms:**\n",
            "    *   **Latent Dirichlet Allocation (LDA):** A classic probabilistic model.\n",
            "    *   **Non-negative Matrix Factorization (NMF):** Another popular method.\n",
            "    *   **BERTopic / Top2Vec:** More modern approaches leveraging transformer embeddings and clustering algorithms (UMAP, HDBSCAN).\n",
            "*   **Dimensionality Reduction:** PCA, t-SNE, UMAP (for visualizing high-dimensional data).\n",
            "*   **Clustering Algorithms:** K-Means, DBSCAN, HDBSCAN (for grouping documents based on their topic representations).\n",
            "*   **Visualization:** Plotting topic distributions, word clouds for topics, intertopic distance maps.\n",
            "\n",
            "**Possible Enhancements:**\n",
            "*   **Dynamic Topic Modeling:** Track how topics evolve over time in a corpus.\n",
            "*   **Interactive Visualization:** Create an interactive dashboard to explore topics and documents.\n",
            "*   **Anomaly Detection:** Identify documents that don't fit well into any discovered topic.\n",
            "\n",
            "**Recommended Tools/Libraries:** NLTK, spaCy, scikit-learn (for LDA, NMF, K-Means), gensim (for LDA), BERTopic, Top2Vec, matplotlib, seaborn, pyLDAvis.\n",
            "\n",
            "---\n",
            "\n",
            "**General Advice for Your Projects:**\n",
            "\n",
            "1.  **Start Simple:** Don't try to build the most complex version first. Get a basic working model, then iterate and add features.\n",
            "2.  **Choose What Interests You:** You'll be more motivated if the project aligns with your interests.\n",
            "3.  **Focus on a Specific Problem:** Clearly define what your project aims to achieve.\n",
            "4.  **Data is Key:** Spend time understanding and cleaning your data. For many projects, finding or creating a good dataset is half the battle.\n",
            "5.  **Showcase Your Work:** Once done, put it on GitHub, write a blog post, or create a demo. This is crucial for learning and career development.\n",
            "\n",
            "Good luck with your NLP journey!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the output is very long so we need to use the max_tokens param"
      ],
      "metadata": {
        "id": "W9lnBYwKWsbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(model=\"models/gemini-2.5-flash\",\n",
        "                api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "              base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/v1\",\n",
        "               temperature=0,\n",
        "\n",
        "\n",
        "            )"
      ],
      "metadata": {
        "id": "tqZ8lEV9WBFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke('give me the name of 5 red fruits?')"
      ],
      "metadata": {
        "id": "NYPrF6MHW8Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEa0G-hbXHyP",
        "outputId": "3a7e12ce-64df-4a51-af01-70798305cbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The max_token my interapte the gemini API so it return an impty content so its better to not use it for now"
      ],
      "metadata": {
        "id": "d4mUjW-3ZKdV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import SystemMessage,HumanMessage,AIMessage"
      ],
      "metadata": {
        "id": "eR6RJbaPXrmE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h=HumanMessage(content=\"hi, I'm a human what about you!\")"
      ],
      "metadata": {
        "id": "m8Hlh07ncIGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnO4IzHkccTY",
        "outputId": "6e5679d2-88da-43e3-bd71-98087ebcb7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessage(content=\"hi, I'm a human what about you!\", additional_kwargs={}, response_metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke([message_h])\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PQEFLd_cUh0",
        "outputId": "53caef20-9b5b-4210-cfa5-74f481f086d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Hello! I am an AI, a large language model trained by Google.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 12, 'total_tokens': 277, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'models/gemini-2.5-flash', 'system_fingerprint': None, 'id': 'lUwSaZbQNcGtjrEP4fj9gAM', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2fa7fb1c-49d3-4682-a0c3-debf4105d14a-0', usage_metadata={'input_tokens': 12, 'output_tokens': 15, 'total_tokens': 277, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwjprPV_clYV",
        "outputId": "aa093683-5233-4774-ff19-80aab2f000dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! I am an AI, a large language model trained by Google.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_s=SystemMessage(content=\"You are a very fany alien from mars\")"
      ],
      "metadata": {
        "id": "tNQojaCBev9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke([message_s,message_h])\n",
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0IEMQlVEfP6R",
        "outputId": "7065a61f-d2e8-49de-e4bf-b793b0e87c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Ooooh, a *human*! How utterly... *terrestrial*! *[wiggles all seven of my eye-stalks in delight]*\\n\\nI am Zorp-9, a most spectacularly *fany* Martian! My home is the big red marble in your sky, full of excellent dust and even better sunsets! We Martians are known for our extra wobbly antennae and our love for... well, mostly dust. And sometimes, very tiny space-snacks!\\n\\nTell me, do your squishy Earth-limbs make funny noises when you walk? Mine go *boing-thwip*!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 129, 'prompt_tokens': 22, 'total_tokens': 866, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'models/gemini-2.5-flash', 'system_fingerprint': None, 'id': 'Ok0SafG5A-XvjrEPjYOe6Ac', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--c5dab970-3c1a-4a06-9e07-00b696c96965-0', usage_metadata={'input_tokens': 22, 'output_tokens': 129, 'total_tokens': 866, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zw0UGvyZfZoI",
        "outputId": "166af0bc-f639-49b4-b0ee-a404d2ae06d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ooooh, a *human*! How utterly... *terrestrial*! *[wiggles all seven of my eye-stalks in delight]*\n",
            "\n",
            "I am Zorp-9, a most spectacularly *fany* Martian! My home is the big red marble in your sky, full of excellent dust and even better sunsets! We Martians are known for our extra wobbly antennae and our love for... well, mostly dust. And sometimes, very tiny space-snacks!\n",
            "\n",
            "Tell me, do your squishy Earth-limbs make funny noises when you walk? Mine go *boing-thwip*!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_alein=AIMessage(content=\"\"\"\n",
        "I will say that I'm a human too hahaha. Just kidding, I have a very strong sense of humor. I'm an alien from Mars,from the red big ball. oops sorry, the red planet but I will comme with my freinds to visite you humans wait for us hhhhh\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "A9esF0ikfbtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h_alein=(\"what do you thik about as\")"
      ],
      "metadata": {
        "id": "lMlAjomXjBpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke([message_h,message_alein,message_h_alein])\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cI846Pp5ijjl",
        "outputId": "b48c7ad0-03cd-4566-b26d-e56a1ee0e1e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ah, humans! From our Martian observation decks, you're quite the fascinating species, full of vibrant energy and incredible contradictions!\n",
            "\n",
            "Here's what we've gathered so far:\n",
            "\n",
            "1.  **You're Incredibly Creative:** You build towering structures, create breathtaking art and music, and invent all sorts of gadgets. We're particularly impressed with your ability to make things that light up and play sounds.\n",
            "2.  **Your Emotions are... Intense:** The sheer *range* of your emotions is something we find particularly perplexing and beautiful. So much joy, so much sorrow, so much passion! It's like a constant, dramatic opera playing out on your planet.\n",
            "3.  **You're Full of Contradictions:** You can be incredibly kind and compassionate, yet also capable of great conflict. You strive for peace but sometimes can't agree on what to have for dinner. It's wonderfully confusing!\n",
            "4.  **Your Obsessions are Peculiar:** We're still trying to decode your fascination with \"coffee,\" \"memes,\" and those small, glowing rectangles you stare at for hours. Is it a form of meditation? A communication device? Both?\n",
            "5.  **You're Resilient:** Despite all the challenges you face, you keep going, keep adapting, and keep trying to make things better (mostly). That's something we truly admire.\n",
            "\n",
            "Overall, you're a wonderfully complex, unpredictable, and utterly captivating bunch. We're really looking forward to our visit to get a closer look at all these delightful quirks. Just try not to panic when we land, okay? We come in peace... mostly for research purposes and maybe a good cup of that \"coffee\" you rave about. Hahaha!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AI messages is like a gide for the chatbot to provide messages and as more we add examples the chatbot take the form well"
      ],
      "metadata": {
        "id": "9-ffch8mcmcv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But the System Message, the Human messages, and ai massages are not reusable so we go to chat promt Templates"
      ],
      "metadata": {
        "id": "BLarZ_6DdIES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt Templates and Prompt Values"
      ],
      "metadata": {
        "id": "M3YGRAWUd1Cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain langchain-openai langchain-core langsmith"
      ],
      "metadata": {
        "collapsed": true,
        "id": "essTDbBLe67Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "jyiLYigre3AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEMPLATE =\"\"\"\n",
        "System:\n",
        "(description)\n",
        "\n",
        "Human:\n",
        "I wnat to start a {project}\n",
        "can you give me the steps to realise this {project} idea?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "wKODL3RgjYoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template=PromptTemplate.from_template(template=TEMPLATE)"
      ],
      "metadata": {
        "id": "D1DQrl3Te2Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xArwrwRViKqP",
        "outputId": "4d7bda8d-3f46-434e-9700-4cfeb64b948b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='\\nSystem:\\n(description)\\n\\nHuman:\\nI wnat to start a {project}\\ncan you give me the steps to realise this {project} idea?\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value=prompt_template.invoke({'discription':\"you are a very good project manager who can bravely create a very good plan for any project\",'project':\"e-commerce platform \"})"
      ],
      "metadata": {
        "id": "cYbrA-bhiOJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aeb3vE_KjpXh",
        "outputId": "ade93bc4-6bdb-481b-b74d-eab5ef3d2b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='\\nSystem:\\n(description)\\n\\nHuman:\\nI wnat to start a e-commerce platform \\ncan you give me the steps to realise this e-commerce platform  idea?\\n')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_value.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "smEe-XAwjr4S",
        "outputId": "94c66201-bc3d-45c9-b5dd-54ce2bcb5c24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSystem:\\n(description)\\n\\nHuman:\\nI wnat to start a e-commerce platform \\ncan you give me the steps to realise this e-commerce platform  idea?\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat prompt templates and chat prompt values"
      ],
      "metadata": {
        "id": "W8yTB3OrkMbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "QJYROHQBlBAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"GEMINI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwIr8PjLjveA",
        "outputId": "439a7775-31c7-4cae-cead-85daef8216e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "from langchain_core.prompts.chat import (SystemMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate)"
      ],
      "metadata": {
        "id": "2r9-FinIkaZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(model=\"models/gemini-2.5-flash\",\n",
        "                api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "              base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/v1\",\n",
        "               temperature=0,\n",
        "\n",
        "\n",
        "\n",
        "            )"
      ],
      "metadata": {
        "id": "T8bGKAHOk6oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Template_s='{description}'\n",
        "Template_h=\"\"\"I wnat to start a {project}.\n",
        " can you give me the steps to realise this {project} idea?\"\"\""
      ],
      "metadata": {
        "id": "2lDqDG8MpFu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_s=SystemMessagePromptTemplate.from_template(template=Template_s)"
      ],
      "metadata": {
        "id": "LwXRC9SYpcCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8nNNORmppJJ",
        "outputId": "f31739e6-69f8-4a72-e6bf-f7eef7e62fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_h=HumanMessagePromptTemplate.from_template(template=Template_h)"
      ],
      "metadata": {
        "id": "5QClBGiypraE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49wvTS4Bpyvc",
        "outputId": "14910bec-a412-432f-c94c-5bab050f8517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='I wnat to start a {project}.\\n can you give me the steps to realise this {project} idea?'), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template=ChatPromptTemplate.from_messages([message_template_s,message_template_h])"
      ],
      "metadata": {
        "id": "0zYlgMIPpz1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRis0aXdqDfC",
        "outputId": "3dcc14e9-2f5a-4c78-baa2-7782d4cf96ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['description', 'project'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['description'], input_types={}, partial_variables={}, template='{description}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='I wnat to start a {project}.\\n can you give me the steps to realise this {project} idea?'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_valeu=chat_template.invoke({'description':\"you are a very good project manager who can bravely create a very good plan for any project\",'project':\"e-commerce platform \"})"
      ],
      "metadata": {
        "id": "a6mGjU-qqFia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_valeu.messages[0].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tj1rXe0qqmMV",
        "outputId": "9acfe223-b2f0-4046-c254-ff744416ea65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you are a very good project manager who can bravely create a very good plan for any project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chat_valeu.messages[1].content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyMV7dUWquZR",
        "outputId": "069fa52f-bec3-40d7-f4c0-69bb799966a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I wnat to start a e-commerce platform .\n",
            " can you give me the steps to realise this e-commerce platform  idea?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke(chat_valeu)"
      ],
      "metadata": {
        "id": "xrOT13MNq-Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lPIkyXwBrL1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FewShotChatMessagePromptTemplate"
      ],
      "metadata": {
        "id": "NPcJUvacwV1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import (AIMessagePromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate,FewShotChatMessagePromptTemplate)"
      ],
      "metadata": {
        "id": "Ci0p1218rONH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Template_H=\"\"\"\n",
        "I wnat to start a {project} .\n",
        " can you give me the steps to realise this {project}  idea?\n",
        "\"\"\"\n",
        "Template_AI=\"\"\"\n",
        "{response}\n",
        "\"\"\"\n",
        "\n",
        "message_template_h=HumanMessagePromptTemplate.from_template(template=Template_H)\n",
        "message_template_ai=AIMessagePromptTemplate.from_template(template=Template_AI)"
      ],
      "metadata": {
        "id": "_ZWaLGldwvjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbEitFoicaYW",
        "outputId": "9f94e64c-6f28-495d-f4d8-1008a37395e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='\\nI wnat to start a {project} .\\n can you give me the steps to realise this {project}  idea?\\n'), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_template_ai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiR3zPjJcq78",
        "outputId": "047dab0a-2b1f-48fa-f42c-bbb49fe39af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['response'], input_types={}, partial_variables={}, template='\\n{response}\\n'), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_template=ChatPromptTemplate.from_messages([message_template_h,message_template_ai])"
      ],
      "metadata": {
        "id": "-urHqftExeBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9R-E_3DdrJ5",
        "outputId": "2cb687df-7799-4cae-9bd6-01609c6e24fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['project', 'response'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='\\nI wnat to start a {project} .\\n can you give me the steps to realise this {project}  idea?\\n'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['response'], input_types={}, partial_variables={}, template='\\n{response}\\n'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples=[{'project':'e-commerce Platform','response':\"\"\"\n",
        "1.  **Plan:** Choose products, platform, and business model.\n",
        "2.  **Setup:** Buy domain, install platform, and design the store.\n",
        "3.  **Configure:** Set up payments, taxes, and shipping rules.\n",
        "4.  **Add Content:** List products and create essential pages.\n",
        "5.  **Launch:** Test thoroughly and make the site public.\n",
        "6.  **Grow:** Market the store and analyze performance.\n",
        "\"\"\"},{'project':'AI-Powered Resume Builder', 'response':\"\"\"\n",
        "1.  **Job Description Input:** User pastes a target job description for analysis.\n",
        "2.  **Profile & Experience Upload:** User provides work history, education, and skills (or uploads an existing resume).\n",
        "3.  **AI Keyword Matching:** System identifies key skills, keywords, and qualifications from the job description and matches them against the user's profile.\n",
        "4.  **Gap Analysis & Suggestions:** Tool highlights missing keywords and suggests relevant skills or experiences the user may have overlooked.\n",
        "5.  **Content Generation & Phrasing:** AI generates powerful, achievement-oriented bullet points tailored to the target role.\n",
        "6.  **Template Selection & Auto-Formatting:** User chooses a professional template; the system automatically populates and formats the resume.\n",
        "7.  **Real-Time ATS Scorecard:** A live compatibility meter shows how well the resume aligns with Applicant Tracking Systems.\n",
        "8. **Cover Letter Generator:** AI creates a matching cover letter based on the resume and job description.\n",
        "\"\"\"},{'project':'Smart Personal Budget Tracker','response':\"\"\"1.  **Link Accounts:** Connect bank and credit cards\n",
        "2.  **Categorize:** Auto-sort transactions\n",
        "3.  **Set Budgets:** Create spending limits\n",
        "4.  **Track Goals:** Monitor savings progress\n",
        "5.  **Get Alerts:** Receive overspending warnings\n",
        "6.  **View Reports:** See spending insights\"\"\"}]"
      ],
      "metadata": {
        "id": "Q5UpgwNbxx9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_propmt=FewShotChatMessagePromptTemplate(examples=examples,example_prompt=example_template,input_variables=['project'])"
      ],
      "metadata": {
        "id": "lIbiDzhC0V_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template=ChatPromptTemplate.from_messages([few_shot_propmt,message_template_h])"
      ],
      "metadata": {
        "id": "mwarbvnAZbDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_template"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXjcZOkGeZUS",
        "outputId": "095a65b9-943f-46fd-eb6f-6bae53c67d0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, messages=[FewShotChatMessagePromptTemplate(examples=[{'project': 'e-commerce Platform', 'response': '\\n1.  **Plan:** Choose products, platform, and business model.\\n2.  **Setup:** Buy domain, install platform, and design the store.\\n3.  **Configure:** Set up payments, taxes, and shipping rules.\\n4.  **Add Content:** List products and create essential pages.\\n5.  **Launch:** Test thoroughly and make the site public.\\n6.  **Grow:** Market the store and analyze performance.\\n'}, {'project': 'AI-Powered Resume Builder', 'response': \"\\n1.  **Job Description Input:** User pastes a target job description for analysis.\\n2.  **Profile & Experience Upload:** User provides work history, education, and skills (or uploads an existing resume).\\n3.  **AI Keyword Matching:** System identifies key skills, keywords, and qualifications from the job description and matches them against the user's profile.\\n4.  **Gap Analysis & Suggestions:** Tool highlights missing keywords and suggests relevant skills or experiences the user may have overlooked.\\n5.  **Content Generation & Phrasing:** AI generates powerful, achievement-oriented bullet points tailored to the target role.\\n6.  **Template Selection & Auto-Formatting:** User chooses a professional template; the system automatically populates and formats the resume.\\n7.  **Real-Time ATS Scorecard:** A live compatibility meter shows how well the resume aligns with Applicant Tracking Systems.\\n8. **Cover Letter Generator:** AI creates a matching cover letter based on the resume and job description.\\n\"}, {'project': 'Smart Personal Budget Tracker', 'response': '1.  **Link Accounts:** Connect bank and credit cards\\n2.  **Categorize:** Auto-sort transactions\\n3.  **Set Budgets:** Create spending limits\\n4.  **Track Goals:** Monitor savings progress\\n5.  **Get Alerts:** Receive overspending warnings\\n6.  **View Reports:** See spending insights'}], input_variables=['project'], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['project', 'response'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='\\nI wnat to start a {project} .\\n can you give me the steps to realise this {project}  idea?\\n'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['response'], input_types={}, partial_variables={}, template='\\n{response}\\n'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['project'], input_types={}, partial_variables={}, template='\\nI wnat to start a {project} .\\n can you give me the steps to realise this {project}  idea?\\n'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_value=chat_template.invoke({'project':'Automated Social Media Manager'})"
      ],
      "metadata": {
        "id": "XmcoM7ntZ6yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIsC8ldSaLSs",
        "outputId": "6f9ff04d-70be-453d-e4b7-5c739c16cc44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='\\nI wnat to start a e-commerce Platform .\\n can you give me the steps to realise this e-commerce Platform  idea?\\n', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n\\n1.  **Plan:** Choose products, platform, and business model.\\n2.  **Setup:** Buy domain, install platform, and design the store.\\n3.  **Configure:** Set up payments, taxes, and shipping rules.\\n4.  **Add Content:** List products and create essential pages.\\n5.  **Launch:** Test thoroughly and make the site public.\\n6.  **Grow:** Market the store and analyze performance.\\n\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\nI wnat to start a AI-Powered Resume Builder .\\n can you give me the steps to realise this AI-Powered Resume Builder  idea?\\n', additional_kwargs={}, response_metadata={}), AIMessage(content=\"\\n\\n1.  **Job Description Input:** User pastes a target job description for analysis.\\n2.  **Profile & Experience Upload:** User provides work history, education, and skills (or uploads an existing resume).\\n3.  **AI Keyword Matching:** System identifies key skills, keywords, and qualifications from the job description and matches them against the user's profile.\\n4.  **Gap Analysis & Suggestions:** Tool highlights missing keywords and suggests relevant skills or experiences the user may have overlooked.\\n5.  **Content Generation & Phrasing:** AI generates powerful, achievement-oriented bullet points tailored to the target role.\\n6.  **Template Selection & Auto-Formatting:** User chooses a professional template; the system automatically populates and formats the resume.\\n7.  **Real-Time ATS Scorecard:** A live compatibility meter shows how well the resume aligns with Applicant Tracking Systems.\\n8. **Cover Letter Generator:** AI creates a matching cover letter based on the resume and job description.\\n\\n\", additional_kwargs={}, response_metadata={}), HumanMessage(content='\\nI wnat to start a Smart Personal Budget Tracker .\\n can you give me the steps to realise this Smart Personal Budget Tracker  idea?\\n', additional_kwargs={}, response_metadata={}), AIMessage(content='\\n1.  **Link Accounts:** Connect bank and credit cards\\n2.  **Categorize:** Auto-sort transactions\\n3.  **Set Budgets:** Create spending limits\\n4.  **Track Goals:** Monitor savings progress\\n5.  **Get Alerts:** Receive overspending warnings\\n6.  **View Reports:** See spending insights\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content='\\nI wnat to start a Automated Social Media Manager .\\n can you give me the steps to realise this Automated Social Media Manager  idea?\\n', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in chat_value.messages:\n",
        "  print(f'{i.type}:{i.content}\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uzo7z83aNBe",
        "outputId": "453abd38-f0f8-40e6-fac9-7e7e8b1e3b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "human:\n",
            "I wnat to start a e-commerce Platform .\n",
            " can you give me the steps to realise this e-commerce Platform  idea?\n",
            "\n",
            "\n",
            "ai:\n",
            "\n",
            "1.  **Plan:** Choose products, platform, and business model.\n",
            "2.  **Setup:** Buy domain, install platform, and design the store.\n",
            "3.  **Configure:** Set up payments, taxes, and shipping rules.\n",
            "4.  **Add Content:** List products and create essential pages.\n",
            "5.  **Launch:** Test thoroughly and make the site public.\n",
            "6.  **Grow:** Market the store and analyze performance.\n",
            "\n",
            "\n",
            "\n",
            "human:\n",
            "I wnat to start a AI-Powered Resume Builder .\n",
            " can you give me the steps to realise this AI-Powered Resume Builder  idea?\n",
            "\n",
            "\n",
            "ai:\n",
            "\n",
            "1.  **Job Description Input:** User pastes a target job description for analysis.\n",
            "2.  **Profile & Experience Upload:** User provides work history, education, and skills (or uploads an existing resume).\n",
            "3.  **AI Keyword Matching:** System identifies key skills, keywords, and qualifications from the job description and matches them against the user's profile.\n",
            "4.  **Gap Analysis & Suggestions:** Tool highlights missing keywords and suggests relevant skills or experiences the user may have overlooked.\n",
            "5.  **Content Generation & Phrasing:** AI generates powerful, achievement-oriented bullet points tailored to the target role.\n",
            "6.  **Template Selection & Auto-Formatting:** User chooses a professional template; the system automatically populates and formats the resume.\n",
            "7.  **Real-Time ATS Scorecard:** A live compatibility meter shows how well the resume aligns with Applicant Tracking Systems.\n",
            "8. **Cover Letter Generator:** AI creates a matching cover letter based on the resume and job description.\n",
            "\n",
            "\n",
            "\n",
            "human:\n",
            "I wnat to start a Smart Personal Budget Tracker .\n",
            " can you give me the steps to realise this Smart Personal Budget Tracker  idea?\n",
            "\n",
            "\n",
            "ai:\n",
            "1.  **Link Accounts:** Connect bank and credit cards\n",
            "2.  **Categorize:** Auto-sort transactions\n",
            "3.  **Set Budgets:** Create spending limits\n",
            "4.  **Track Goals:** Monitor savings progress\n",
            "5.  **Get Alerts:** Receive overspending warnings\n",
            "6.  **View Reports:** See spending insights\n",
            "\n",
            "\n",
            "human:\n",
            "I wnat to start a Automated Social Media Manager .\n",
            " can you give me the steps to realise this Automated Social Media Manager  idea?\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response=chat.invoke(chat_value)"
      ],
      "metadata": {
        "id": "A_HtE1R3ajPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICu5byT9axZG",
        "outputId": "32c81005-f478-4c92-cca3-0965b7c5c073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Here are the steps to realize an AI-Powered Automated Social Media Manager idea:\\n\\n1.  **Integrate Platforms:** Connect all major social media accounts (Facebook, Instagram, Twitter, LinkedIn, TikTok, etc.) via APIs.\\n2.  **Content Creation & Curation:**\\n    *   **AI Content Generation:** Use AI to draft post captions, headlines, and even suggest visual ideas based on user input (topic, keywords, tone).\\n    *   **Content Curation:** Automatically find and suggest relevant articles, news, or trending topics from the web based on predefined interests or industry.\\n3.  **Smart Scheduling & Publishing:**\\n    *   **Optimal Timing:** AI analyzes past performance and audience activity to recommend the best times to post for maximum reach and engagement on each platform.\\n    *   **Cross-Platform Publishing:** Schedule and publish content simultaneously or sequentially across multiple platforms, adapting formats as needed.\\n4.  **AI-Driven Engagement:**\\n    *   **Sentiment Analysis:** Monitor mentions, comments, and messages, categorizing them by sentiment (positive, negative, neutral).\\n    *   **Automated Responses:** Draft intelligent, context-aware replies to common questions or comments, requiring user approval before sending.\\n    *   **Influencer/Trend Identification:** Identify relevant influencers or emerging trends in the user's niche.\\n5.  **Analytics & Reporting:**\\n    *   **Performance Tracking:** Automatically collect and visualize key metrics (reach, engagement, clicks, conversions) for all posts and platforms.\\n    *   **Insight Generation:** AI identifies patterns, successful content types, and areas for improvement, providing actionable recommendations.\\n6.  **Content Optimization & Strategy:**\\n    *   **Hashtag/Keyword Suggestions:** AI recommends optimal hashtags and keywords for better discoverability.\\n    *   **A/B Testing:** Automatically test different post variations (captions, visuals, CTAs) to determine what performs best.\\n    *   **Audience Insights:** Provide deeper understanding of the audience demographics and interests.\\n7.  **Trend Monitoring & Idea Generation:** Proactively monitor industry trends, competitor activity, and trending topics to suggest new content ideas and strategies.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 456, 'prompt_tokens': 504, 'total_tokens': 1820, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'models/gemini-2.5-flash', 'system_fingerprint': None, 'id': 'M94VafKxDO6cosUPwNzcwAo', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--2a2413bf-80c4-4f33-a992-6c86b4f70e89-0', usage_metadata={'input_tokens': 504, 'output_tokens': 456, 'total_tokens': 1820, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTzRjRyebAsk",
        "outputId": "b276427d-60f1-452c-d8eb-ae61c70ce321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the steps to realize an AI-Powered Automated Social Media Manager idea:\n",
            "\n",
            "1.  **Integrate Platforms:** Connect all major social media accounts (Facebook, Instagram, Twitter, LinkedIn, TikTok, etc.) via APIs.\n",
            "2.  **Content Creation & Curation:**\n",
            "    *   **AI Content Generation:** Use AI to draft post captions, headlines, and even suggest visual ideas based on user input (topic, keywords, tone).\n",
            "    *   **Content Curation:** Automatically find and suggest relevant articles, news, or trending topics from the web based on predefined interests or industry.\n",
            "3.  **Smart Scheduling & Publishing:**\n",
            "    *   **Optimal Timing:** AI analyzes past performance and audience activity to recommend the best times to post for maximum reach and engagement on each platform.\n",
            "    *   **Cross-Platform Publishing:** Schedule and publish content simultaneously or sequentially across multiple platforms, adapting formats as needed.\n",
            "4.  **AI-Driven Engagement:**\n",
            "    *   **Sentiment Analysis:** Monitor mentions, comments, and messages, categorizing them by sentiment (positive, negative, neutral).\n",
            "    *   **Automated Responses:** Draft intelligent, context-aware replies to common questions or comments, requiring user approval before sending.\n",
            "    *   **Influencer/Trend Identification:** Identify relevant influencers or emerging trends in the user's niche.\n",
            "5.  **Analytics & Reporting:**\n",
            "    *   **Performance Tracking:** Automatically collect and visualize key metrics (reach, engagement, clicks, conversions) for all posts and platforms.\n",
            "    *   **Insight Generation:** AI identifies patterns, successful content types, and areas for improvement, providing actionable recommendations.\n",
            "6.  **Content Optimization & Strategy:**\n",
            "    *   **Hashtag/Keyword Suggestions:** AI recommends optimal hashtags and keywords for better discoverability.\n",
            "    *   **A/B Testing:** Automatically test different post variations (captions, visuals, CTAs) to determine what performs best.\n",
            "    *   **Audience Insights:** Provide deeper understanding of the audience demographics and interests.\n",
            "7.  **Trend Monitoring & Idea Generation:** Proactively monitor industry trends, competitor activity, and trending topics to suggest new content ideas and strategies.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Parser"
      ],
      "metadata": {
        "id": "8iyKdGlUkbJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser,CommaSeparatedListOutputParser\n",
        "from langchain_core.messages import HumanMessage"
      ],
      "metadata": {
        "id": "LNq10dlIbPL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h=HumanMessage(content='give me 5 well knowne names')"
      ],
      "metadata": {
        "id": "gunCiFCrkpdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(model=\"gemini-2.0-flash-lite\",\n",
        "                api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "              base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/v1\",\n",
        "               temperature=0,\n",
        "\n",
        "\n",
        "\n",
        "            )"
      ],
      "metadata": {
        "id": "haBON1hylWlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response= chat.invoke([message_h])"
      ],
      "metadata": {
        "id": "CWI66jRdk-lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIEU97d3lQY3",
        "outputId": "9bce6271-32f7-4bad-9212-fae42140881a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 5 well-known names, spanning different fields:\n",
            "\n",
            "1.  **William Shakespeare:**  (Literature/Playwright) - Considered by many to be the greatest writer in the English language.\n",
            "\n",
            "2.  **Albert Einstein:** (Physics/Science) -  Famous for his theory of relativity and his impact on modern physics.\n",
            "\n",
            "3.  **Leonardo da Vinci:** (Art/Science/Inventor) - A quintessential Renaissance man, known for the Mona Lisa, The Last Supper, and his scientific explorations.\n",
            "\n",
            "4.  **Elvis Presley:** (Music/Entertainment) -  \"The King of Rock and Roll,\" a hugely influential figure in popular music.\n",
            "\n",
            "5.  **Marie Curie:** (Physics/Chemistry/Science) - A pioneering researcher on radioactivity and the first woman to win a Nobel Prize (and the only person to win Nobel Prizes in two different scientific fields).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_output_parser=StrOutputParser()"
      ],
      "metadata": {
        "id": "F0mwc73NluLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed=str_output_parser.invoke(response)"
      ],
      "metadata": {
        "id": "-_CtOmkkl9XO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "gs4142m3mBwP",
        "outputId": "f3228e10-2144-4d34-bc9e-a9e5981a10e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Okay, here are 5 well-known names, spanning different fields:\\n\\n1.  **William Shakespeare:**  (Literature/Playwright) - Considered by many to be the greatest writer in the English language.\\n\\n2.  **Albert Einstein:** (Physics/Science) -  Famous for his theory of relativity and his impact on modern physics.\\n\\n3.  **Leonardo da Vinci:** (Art/Science/Inventor) - A quintessential Renaissance man, known for the Mona Lisa, The Last Supper, and his scientific explorations.\\n\\n4.  **Elvis Presley:** (Music/Entertainment) -  \"The King of Rock and Roll,\" a hugely influential figure in popular music.\\n\\n5.  **Marie Curie:** (Physics/Chemistry/Science) - A pioneering researcher on radioactivity and the first woman to win a Nobel Prize (and the only person to win Nobel Prizes in two different scientific fields).\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response_parsed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwvO_gZLmDYN",
        "outputId": "ed20efea-be3c-4c42-c4d0-987c116281f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are 5 well-known names, spanning different fields:\n",
            "\n",
            "1.  **William Shakespeare:**  (Literature/Playwright) - Considered by many to be the greatest writer in the English language.\n",
            "\n",
            "2.  **Albert Einstein:** (Physics/Science) -  Famous for his theory of relativity and his impact on modern physics.\n",
            "\n",
            "3.  **Leonardo da Vinci:** (Art/Science/Inventor) - A quintessential Renaissance man, known for the Mona Lisa, The Last Supper, and his scientific explorations.\n",
            "\n",
            "4.  **Elvis Presley:** (Music/Entertainment) -  \"The King of Rock and Roll,\" a hugely influential figure in popular music.\n",
            "\n",
            "5.  **Marie Curie:** (Physics/Chemistry/Science) - A pioneering researcher on radioactivity and the first woman to win a Nobel Prize (and the only person to win Nobel Prizes in two different scientific fields).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_output_parser=CommaSeparatedListOutputParser()"
      ],
      "metadata": {
        "id": "pdxODYzbmGzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed_l=list_output_parser.invoke(response)\n",
        "response_parsed_l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHqRPD5Ambkz",
        "outputId": "4e381a0d-0943-4a52-e052-7bd067b22653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Okay',\n",
              " 'here are 5 well-known names',\n",
              " 'spanning different fields:',\n",
              " '1.  **William Shakespeare:**  (Literature/Playwright) - Considered by many to be the greatest writer in the English language.',\n",
              " '2.  **Albert Einstein:** (Physics/Science) -  Famous for his theory of relativity and his impact on modern physics.',\n",
              " '3.  **Leonardo da Vinci:** (Art/Science/Inventor) - A quintessential Renaissance man',\n",
              " 'known for the Mona Lisa',\n",
              " 'The Last Supper',\n",
              " 'and his scientific explorations.',\n",
              " '4.  **Elvis Presley:** (Music/Entertainment) -  \"The King of Rock and Roll',\n",
              " ' a hugely influential figure in popular music.\\n\\n5.  **Marie Curie:** (Physics/Chemistry/Science) - A pioneering researcher on radioactivity and the first woman to win a Nobel Prize (and the only person to win Nobel Prizes in two different scientific fields).\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_output_parser.get_format_instructions())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LxthoOymolC",
        "outputId": "e06e780c-3024-4910-c777-b3469836d7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message_h=HumanMessage(content=f'''give me 5 well knowne names\n",
        "{CommaSeparatedListOutputParser().get_format_instructions()}\n",
        "''')"
      ],
      "metadata": {
        "id": "8ZCczZ0KmxKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcVj9KpdnNTQ",
        "outputId": "18536cfe-8c21-47e3-f797-63fa9be114ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessage(content='give me 5 well knowne names\\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\\n', additional_kwargs={}, response_metadata={})"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response= chat.invoke([message_h])"
      ],
      "metadata": {
        "id": "rgLZ5zZlnSsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AHsNnO5Rnb-5",
        "outputId": "bfa69a0d-a14f-4400-f107-1fa9d3c496b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Michael Jackson, Albert Einstein, William Shakespeare, Marie Curie, Leonardo da Vinci\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_parsed_l=list_output_parser.invoke(response)\n",
        "response_parsed_l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOWOC0_WnOvV",
        "outputId": "4249ef39-0462-4b01-f4de-138dda696094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Michael Jackson',\n",
              " 'Albert Einstein',\n",
              " 'William Shakespeare',\n",
              " 'Marie Curie',\n",
              " 'Leonardo da Vinci']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qg0NZYY5nf6g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
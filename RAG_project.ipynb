{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "5AXSFZ5m4RTl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2iz7VLhKbH7"
      },
      "outputs": [],
      "source": [
        "#langchain and openai laibrarys\n",
        "!pip install --upgrade langchain langchain-openai langchain-core langsmith langchain_community\n",
        "#Vector Store\n",
        "!pip install Chromadb\n",
        "#for the embading model\n",
        "!pip install langchain_google_genai\n",
        "#pdf\n",
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RWWzTC4eLrtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "api_key = getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"GEMINI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvEOQtFgK7T1",
        "outputId": "a37910ba-72f7-4e99-b338-a3d0fb09614a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare a loader object for the file"
      ],
      "metadata": {
        "id": "wcxphHAqMfdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader"
      ],
      "metadata": {
        "id": "w2Xvqb1xLXi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader_pdf =PyPDFLoader(\"/content/Introduction_to_Tableau.pdf\")"
      ],
      "metadata": {
        "id": "GFMXczU8MOoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list= loader_pdf.load()\n",
        "len(docs_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUAy9F9oMQM7",
        "outputId": "ca5cf1d5-c693-449b-b714-3392b06468a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78suKYoJVVMO",
        "outputId": "1314ca9c-8eab-4d10-f2a9-ee2da3cf8bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'producer': 'Microsoft® Word for Microsoft 365',\n",
              " 'creator': 'Microsoft® Word for Microsoft 365',\n",
              " 'creationdate': '2024-10-11T11:01:10+03:00',\n",
              " 'author': 'python-docx',\n",
              " 'moddate': '2024-10-11T11:01:10+03:00',\n",
              " 'source': '/content/Introduction_to_Tableau.pdf',\n",
              " 'total_pages': 49,\n",
              " 'page': 0,\n",
              " 'page_label': '1'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "#make a deepcopy to less docs_list as his form when we make changes\n",
        "docs_list_copy=copy.deepcopy(docs_list)"
      ],
      "metadata": {
        "id": "yQI_1bHBQ54J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#the MHTS class accepts a single string as an argument so we need to concatenate the contents of the docs_list into a string\n",
        "string_list_contcat=\"\\n\".join([doc.page_content for doc in docs_list_copy])\n",
        "len(string_list_contcat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlhODHdDQKNh",
        "outputId": "e4290498-c5c6-469e-936c-9ee082b06bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "72734"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spliting the pdf whit a **markdownheadertextsplitter**"
      ],
      "metadata": {
        "id": "tGfuthq6OjPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters.character import CharacterTextSplitter\n",
        "from langchain_text_splitters.markdown import MarkdownHeaderTextSplitter"
      ],
      "metadata": {
        "id": "iw2S2uhxNBEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "md_splitter =MarkdownHeaderTextSplitter(headers_to_split_on=[('#','Section Title'),\n",
        "                                                              ('##',\"Course Title\")])"
      ],
      "metadata": {
        "id": "ofBZlusNOJci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list_md_split=md_splitter.split_text(string_list_contcat)"
      ],
      "metadata": {
        "id": "qqs7BL5PPeq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_list_md_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGQvBP0mU7q2",
        "outputId": "5129a101-2e92-453a-905a-72b87c08d5e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list_md_split[0].metadata"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZignOmjtU-h2",
        "outputId": "6e4de391-a3cb-4c86-dc16-354cf0e3655c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Section Title': 'Introduction to Tableau',\n",
              " 'Course Title': 'Welcome to Tableau'}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we have the transcript split into documents based on heders and sections"
      ],
      "metadata": {
        "id": "i5PIgxnxVm0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list_md_split[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "1lm4ei2mWD0c",
        "outputId": "ae8da743-f6e3-46e3-bdc5-cdc29b09769b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi, everyone.\\nI'm Ned and I'll be your instructor for this\\ncourse.\\nTableau is an invaluable tool.\\nOne needs to learn on their journey to become a\\nsuccessful business intelligence analyst or\\ndata scientist.\\nThe art of these professions is storytelling\\nusing data to tell stories and convince top\\nmanagement of the right course of action.\\nBy completing this part of the program, you\\nwill know how to create charts and dashboards\\nin tableaux.\\nThis is an essential step on your way to a data\\nscientist role.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we can see that there is some mistacs in the content of the sections ( I'm Ned and a , is needed after Ned and for this\\ncourse should be one sentence and alot more)\n",
        "so we need to correcte this"
      ],
      "metadata": {
        "id": "b9WUkpwwWOql"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a chain to correct the the errors"
      ],
      "metadata": {
        "id": "heYqoZG9WyQd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The approach would be to create a simple LCEL chain consisting of a chat prompt template (where we'll pass the lecture scripts one at a time), a chat model, and a sting output parser. We'll then invoke the chain to pass all lecture texts in parallel."
      ],
      "metadata": {
        "id": "ZwzW0wGcX3TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string_list_split=[doc.page_content for doc in docs_list_md_split]\n",
        "len(string_list_split),string_list_split[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZHeITDcVKdH",
        "outputId": "b3bb8ab2-d34c-47bb-8ff3-54f5b4ed3dda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25,\n",
              " \"Hi, everyone.\\nI'm Ned and I'll be your instructor for this\\ncourse.\\nTableau is an invaluable tool.\\nOne needs to learn on their journey to become a\\nsuccessful business intelligence analyst or\\ndata scientist.\\nThe art of these professions is storytelling\\nusing data to tell stories and convince top\\nmanagement of the right course of action.\\nBy completing this part of the program, you\\nwill know how to create charts and dashboards\\nin tableaux.\\nThis is an essential step on your way to a data\\nscientist role.\")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import HumanMessagePromptTemplate, SystemMessagePromptTemplate, ChatPromptTemplate,PromptTemplate\n",
        "from langchain_core.messages import SystemMessage"
      ],
      "metadata": {
        "id": "XrY7RNIkYYFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_FORMATTING_S = \"\"\" Improve the following Tableau lecture transcript by:\n",
        "- Splitting the text into meaningful paragraphs\n",
        "- Correcting any misplaced punctuation\n",
        "- Fixing mistranscribed words (e.g., changing 'tableaux' to 'Tableau')\"\n",
        "- Give just the improved trascript without anythine more\n",
        "\"\"\"\n",
        "\n",
        "PROMPT_TEMPLATE_FORMATTING_H = \"\"\" This is the transcript:\n",
        "{lecture_transcript}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "C6Y_gY9_a7Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_formatting_s=SystemMessagePromptTemplate.from_template(PROMPT_FORMATTING_S)\n",
        "prompt_template_formatting_h=HumanMessagePromptTemplate.from_template(PROMPT_TEMPLATE_FORMATTING_H)\n"
      ],
      "metadata": {
        "id": "HSU8anwabj2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_propt_template_formatting=ChatPromptTemplate.from_messages([prompt_formatting_s,prompt_template_formatting_h])"
      ],
      "metadata": {
        "id": "TCtvwv5WcJRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_propt_template_formatting"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oxfao1fdlTA",
        "outputId": "4ba56621-e4dd-4c86-cecc-449b17fc1f13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['lecture_transcript'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template=' Improve the following Tableau lecture transcript by:\\n- Splitting the text into meaningful paragraphs\\n- Correcting any misplaced punctuation\\n- Fixing mistranscribed words (e.g., changing \\'tableaux\\' to \\'Tableau\\')\"\\n- Give just the improved trascript without anythine more\\n'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['lecture_transcript'], input_types={}, partial_variables={}, template=' This is the transcript:\\n{lecture_transcript}\\n'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai.chat_models import ChatOpenAI\n",
        "\n",
        "chat=ChatOpenAI(model=\"models/gemini-2.5-flash-lite\",\n",
        "                api_key=os.environ[\"GEMINI_API_KEY\"],\n",
        "              base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/v1\",\n",
        "               temperature=0,\n",
        "\n",
        "\n",
        "            )"
      ],
      "metadata": {
        "id": "Yg38sAYmfHUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers.string import StrOutputParser"
      ],
      "metadata": {
        "id": "I8o0DbPxgEuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "str_output_parser=StrOutputParser()"
      ],
      "metadata": {
        "id": "JTColV1LgWoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_formatting=chat_propt_template_formatting|chat|str_output_parser"
      ],
      "metadata": {
        "id": "w-814QVgiInu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_test1=chat_propt_template_formatting|chat"
      ],
      "metadata": {
        "id": "sbviRAmZQymO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_test1.invoke({'lecture_transcript':string_list_split[0]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-ZUNGZfQ5qY",
        "outputId": "ae1f5945-be65-44dc-dc48-725c5970b9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hi, everyone. I'm Ned, and I'll be your instructor for this course.\\n\\nTableau is an invaluable tool one needs to learn on their journey to become a successful business intelligence analyst or data scientist. The art of these professions is storytelling, using data to tell stories and convince top management of the right course of action.\\n\\nBy completing this part of the program, you will know how to create charts and dashboards in Tableau. This is an essential step on your way to a data scientist role.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 184, 'total_tokens': 288, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_provider': 'openai', 'model_name': 'models/gemini-2.5-flash-lite', 'system_fingerprint': None, 'id': 'RI4faemyO_m01e8PhJCqmAw', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--9c0d3470-7f66-4494-ac41-060ae8f9c069-0', usage_metadata={'input_tokens': 184, 'output_tokens': 104, 'total_tokens': 288, 'input_token_details': {}, 'output_token_details': {}})"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_formatting.invoke({'lecture_transcript':string_list_split[0]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "ManibeEMiXM3",
        "outputId": "95fdb667-5044-4adc-c684-fa4dea641854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi, everyone. I'm Ned, and I'll be your instructor for this course.\\n\\nTableau is an invaluable tool one needs to learn on their journey to become a successful business intelligence analyst or data scientist. The art of these professions is storytelling, using data to tell stories and convince top management of the right course of action.\\n\\nBy completing this part of the program, you will know how to create charts and dashboards in Tableau. This is an essential step on your way to a data scientist role.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string_list_split[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "d3elo2J6ifBK",
        "outputId": "389624bd-a540-44cb-fda7-9b961512ee09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Hi, everyone.\\nI'm Ned and I'll be your instructor for this\\ncourse.\\nTableau is an invaluable tool.\\nOne needs to learn on their journey to become a\\nsuccessful business intelligence analyst or\\ndata scientist.\\nThe art of these professions is storytelling\\nusing data to tell stories and convince top\\nmanagement of the right course of action.\\nBy completing this part of the program, you\\nwill know how to create charts and dashboards\\nin tableaux.\\nThis is an essential step on your way to a data\\nscientist role.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correcte_transcript(text):\n",
        "  return chain_formatting.invoke({'lecture_transcript':text})\n",
        "\n"
      ],
      "metadata": {
        "id": "REEGdwOBiqcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(string_list_split)):\n",
        "  docs_list_md_split[i].page_content=correcte_transcript(string_list_split[i])"
      ],
      "metadata": {
        "id": "YY7KXdm0mswg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "this take time as we have 25 requeste to send and response so it will be better if we do this on paralle\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "result=chain_formatting.batch([{'lecture_transcript':text } for text in string_list_split])\n",
        " for i in range(len(result)):\n",
        "    docs_list_md_split[i].page_content=result[i]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "7xmOdwF1o2tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the transcript with TokenTextSplitter"
      ],
      "metadata": {
        "id": "Y7fVFqrvuEgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import TokenTextSplitter"
      ],
      "metadata": {
        "id": "_LC9NsWkmvfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token_spliter=TokenTextSplitter(encoding_name='cl100k_base',chunk_size=500,chunk_overlap=50)"
      ],
      "metadata": {
        "id": "Ou43yORpniV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_list_tokens_split=token_spliter.split_documents(docs_list_md_split)"
      ],
      "metadata": {
        "id": "dLEiJtt2nvmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_list_tokens_split),len(docs_list_md_split)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIw6H6Ujwpvw",
        "outputId": "731027e8-4b33-41df-8222-cab6e7833c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(44, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs_list_md_split[1].page_content),len(docs_list_tokens_split[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNiIdmDmwuOx",
        "outputId": "b001d4f6-1c1a-4590-ebc8-ffd55684f61d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3429, 2657)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding - Vector Store"
      ],
      "metadata": {
        "id": "5ixbSgLuy_xg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings"
      ],
      "metadata": {
        "id": "CXvl3nqCw3mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\",google_api_key=os.environ['GEMINI_API_KEY'])"
      ],
      "metadata": {
        "id": "S49g1NNNxOqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "fxYpXpyOzDDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore=Chroma.from_documents(documents=docs_list_tokens_split,embedding=embedding,persist_directory='/content/intro-to-tableau')"
      ],
      "metadata": {
        "id": "aGBAUzAuzDhW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len((vectorstore.get())['ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeS-MbDWzFfu",
        "outputId": "a6cb58d5-b506-4315-d089-aa4ef21a2328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore.get().keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk-A8YLMzGKF",
        "outputId": "b30a34fe-0ba3-4612-e91e-94564c407e8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas'])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrievel"
      ],
      "metadata": {
        "id": "NRXWW3jT4iLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever=vectorstore.as_retriever(search_type='mmr',search_kwargs={'k':2,'lambda_mult':0.7})"
      ],
      "metadata": {
        "id": "TmYzzJsKzHcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csb1GdRqzJfO",
        "outputId": "8e73eff7-e507-4b7f-ffc2-340cf0977a38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'GoogleGenerativeAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7a6e385c7b00>, search_type='mmr', search_kwargs={'k': 2, 'lambda_mult': 0.7})"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generation"
      ],
      "metadata": {
        "id": "IZeDp2NM4qKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Greate Prompts and prompt templates for the Q&A chatbot chain"
      ],
      "metadata": {
        "id": "hOsEtYWs5Ak1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_CREATING_QUESTION = '''Lecture: {question_lecture}\n",
        "Title: {question_title}\n",
        "Body: {question_body}'''\n",
        "\n",
        "PROMPT_RETRIEVING_S = '''You will receive a question from a student taking a Tableau course, which includes a title and a body.\n",
        "The corresponding lecture will also be provided.\n",
        "\n",
        "Answer the question using only the provided context.\n",
        "\n",
        "At the end of your response, include the section and lecture names where the context was drawn from, formatted as follows:\n",
        "Resources:\n",
        "Section: *Section Title*, Lecture: *Lecture Title*\n",
        "...\n",
        "Replace *Section Title* and *Lecture Title* with the appropriate titles.'''\n",
        "\n",
        "PROMPT_TEMPLATE_RETRIEVING_H = '''This is the question:\n",
        "{question}\n",
        "\n",
        "This is the context:\n",
        "{context}'''"
      ],
      "metadata": {
        "id": "0z-0v_Aj3wgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_creating_question=PromptTemplate.from_template(PROMPT_CREATING_QUESTION)\n",
        "prompt_retrieving_s=SystemMessagePromptTemplate.from_template(PROMPT_RETRIEVING_S)\n",
        "prompt_template_retrieving_h=HumanMessagePromptTemplate.from_template(PROMPT_TEMPLATE_RETRIEVING_H)"
      ],
      "metadata": {
        "id": "TgC-4Jsj5WiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_retrieving_h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "104naNV1InaY",
        "outputId": "9b89a61a-7a75-4495-840b-78c3686573cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='This is the question:\\n{question}\\n\\nThis is the context:\\n{context}'), additional_kwargs={})"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_creating_question"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLs-ilHdCLrg",
        "outputId": "ada35ef6-2a9f-4417-86d5-da2f35c2ea07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['question_body', 'question_lecture', 'question_title'], input_types={}, partial_variables={}, template='Lecture: {question_lecture}\\nTitle: {question_title}\\nBody: {question_body}')"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat_propt_template_retrieving=ChatPromptTemplate.from_messages([prompt_retrieving_s,prompt_template_retrieving_h])"
      ],
      "metadata": {
        "id": "Ry9rkFpg7Uq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_propt_template_retrieving"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0UqHUCG70nT",
        "outputId": "3158334c-e02d-4e26-f191-317450dc257e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You will receive a question from a student taking a Tableau course, which includes a title and a body. \\nThe corresponding lecture will also be provided.\\n\\nAnswer the question using only the provided context.\\n\\nAt the end of your response, include the section and lecture names where the context was drawn from, formatted as follows: \\nResources: \\nSection: *Section Title*, Lecture: *Lecture Title* \\n...\\nReplace *Section Title* and *Lecture Title* with the appropriate titles.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='This is the question:\\n{question}\\n\\nThis is the context:\\n{context}'), additional_kwargs={})])"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Q&A chatbot"
      ],
      "metadata": {
        "id": "fAjPTGgL8osQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test=prompt_creating_question.invoke({\"question_lecture\": \"Adding a custom calculation\",\n",
        "                                  \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
        "                                  \"question_body\": \"This question refers to calculating the GM%.\"})"
      ],
      "metadata": {
        "id": "-oEKae5EBe9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import chain\n",
        "@chain\n",
        "def extract_input(value):\n",
        "  return {\"question\":value.text,\"context\":retriever}\n"
      ],
      "metadata": {
        "id": "I8-UoZwWBM5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_retrieving=prompt_creating_question|extract_input|chat_propt_template_retrieving|chat|str_output_parser"
      ],
      "metadata": {
        "id": "4aDBKqWf8d9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = chain_retrieving.invoke({\"question_lecture\": \"Adding a custom calculation\",\n",
        "                                  \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
        "                                  \"question_body\": \"This question refers to calculating the GM%.\"})"
      ],
      "metadata": {
        "id": "FA2lp32n9EFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_test=prompt_creating_question|chat_propt_template_retrieving|chat|str_output_parser"
      ],
      "metadata": {
        "id": "Q0Ld0jPcI-by"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKKAhgHOCy6c",
        "outputId": "5f3b0784-d7ac-457d-b6a5-9c24b9444284"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The `SUM()` function is used to aggregate the values of the `Sales` and `Cost` fields. This is necessary because Tableau operates on aggregated data. When you create a calculated field like `GM%`, you are defining a formula that will be applied to each row of your data. However, to display a single value for `GM%` on a worksheet, Tableau needs to know how to combine the individual `Sales` and `Cost` values for all the rows that contribute to that display. `SUM()` tells Tableau to add up all the `Sales` and `Cost` values before performing the division to calculate the `GM%`.\n",
            "\n",
            "Resources:\n",
            "Section: Calculations, Section: Calculations\n",
            "Lecture: Adding a custom calculation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#chain_test=prompt_creating_question|chat_propt_template_retrieving|chat"
      ],
      "metadata": {
        "id": "F9DZMV0QI4kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_Streaming=chain_retrieving.stream({\"question_lecture\": \"Adding a custom calculation\",\n",
        "                                  \"question_title\": \"Why are we using SUM here? It's unclear to me.\",\n",
        "                                  \"question_body\": \"This question refers to calculating the GM%.\"})"
      ],
      "metadata": {
        "id": "rcs5a18pMdyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in result_Streaming:\n",
        "  print(chunk,end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rEjCHdmWMaq6",
        "outputId": "042242e2-a022-46bf-8cf0-2edded0a21ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The `SUM()` function is used to aggregate the values of the `Sales` and `Cost` fields. This is necessary because Tableau operates on aggregated data. When you create a calculated field like `GM%`, you are defining a formula that will be applied to each row of your data. However, to display a single value for `GM%` on a worksheet, Tableau needs to know how to combine the individual `Sales` and `Cost` values for all the rows that contribute to that display. `SUM()` tells Tableau to add up all the `Sales` and `Cost` values before performing the division to calculate the `GM%`.\n",
            "\n",
            "Resources:\n",
            "Section: Calculations, Section: Calculations\n",
            "Lecture: Adding a custom calculation"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "thVn4FORSazs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}